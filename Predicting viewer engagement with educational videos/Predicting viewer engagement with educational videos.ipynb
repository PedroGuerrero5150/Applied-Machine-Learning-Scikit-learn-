{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0be71ec1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ddd869ec642dbe6404672b445fd4dd1",
     "grade": false,
     "grade_id": "cell-6757b7ecd16ad875",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Predicting and understanding viewer engagement with educational videos \n",
    "\n",
    "## About the prediction problem\n",
    "\n",
    "One critical property of a video is engagement: how interesting or \"engaging\" it is for viewers, so that they decide to keep watching. One common approach is to estimate engagement is by measuring how much of the video a user watches. If the video is not interesting and does not engage a viewer, they will typically abandon it quickly, e.g. only watch 5 or 10% of the total. \n",
    "\n",
    "The excercise consists of predicting which educational video is likely to be engaging for viewers, based on a set of features extracted from the video's transcript, audio track, hosting site, and other sources.\n",
    "\n",
    "This problem\n",
    "\n",
    "* It combines a variety of features derived from a rich set of resources connected to the original data;\n",
    "* The manageable dataset size means the dataset and supervised models for it can be easily explored on a wide variety of computing platforms;\n",
    "* Predicting popularity or engagement for a media item, especially combined with understanding which features contribute to its success with viewers, is a fun problem but also a practical representative application of machine learning in a number of business and educational sectors.\n",
    "\n",
    "\n",
    "## About the dataset\n",
    "Datasets put together by researcher Sahan Bulathwela at University College London.\n",
    "\n",
    "The target variable is `engagement` which was defined as True if the median percentage of the video watched across all viewers was at least 30%, and False otherwise.\n",
    "\n",
    "\n",
    "**File descriptions** \n",
    "    assets/train.csv <br>\n",
    "    assets/test.csv \n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv:\n",
    "\n",
    "    title_word_count - the number of words in the title of the video.\n",
    "    \n",
    "    document_entropy - a score indicating how varied the topics are covered in the video, based on the transcript. Videos with smaller entropy scores will tend to be more cohesive and more focused on a single topic.\n",
    "    \n",
    "    freshness - The number of days elapsed between 01/01/1970 and the lecture published date. Videos that are more recent will have higher freshness values.\n",
    "    \n",
    "    easiness - A text difficulty measure applied to the transcript. A lower score indicates more complex language used by the presenter.\n",
    "    \n",
    "    fraction_stopword_presence - A stopword is a very common word like 'the' or 'and'. This feature computes the fraction of all words that are stopwords in the video lecture transcript.\n",
    "    \n",
    "    speaker_speed - The average speaking rate in words per minute of the presenter in the video.\n",
    "    \n",
    "    silent_period_rate - The fraction of time in the lecture video that is silence (no speaking).\n",
    "    \n",
    "train.csv only:\n",
    "    \n",
    "    engagement - Target label for training. True if learners watched a substantial portion of the video (see description), or False otherwise.\n",
    "    \n",
    "\n",
    "## Evaluation\n",
    "\n",
    "\n",
    "Evaluation metric for this assignment: Area Under the ROC Curve (AUC). \n",
    "\n",
    "Main function return a Pandas Series object of length 2309 with the data being the probability that each corresponding video from `readonly/test.csv` will be engaging (according to a model learned from the 'engagement' label in the training set), and the video index being in the `id` field.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1218318f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7dc38d94db79fb7160854a629c825a8",
     "grade": false,
     "grade_id": "cell-2c0cf4e0ffe5f447",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d179ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aef89dbca058b3768c5e369581c14bbb",
     "grade": false,
     "grade_id": "cell-f8da4477c345bf17",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. AUC):  {'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 7, 'max_features': 'log2'}\n",
      "Grid best score (AUC):  0.8463674026967425\n",
      "AUC SCORE (test): 0.810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "9240     0.009852\n",
       "9241     0.084878\n",
       "9242     0.033992\n",
       "9243     0.904762\n",
       "9244     0.033992\n",
       "           ...   \n",
       "11544    0.033992\n",
       "11545    0.009852\n",
       "11546    0.009852\n",
       "11547    0.746154\n",
       "11548    0.033992\n",
       "Length: 2309, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def grid_search(clf, grid_values, X_train, y_train):\n",
    "    grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc', cv=5)\n",
    "    grid_clf_auc.fit(X_train, y_train)\n",
    "    #y_decision_fn_scores_auc = grid_clf_auc.decision_function(X_test) \n",
    "\n",
    "    #print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "    print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "    print('Grid best train score (AUC): ', grid_clf_auc.best_score_)\n",
    "\n",
    "\n",
    "def engagement_model():\n",
    "    # df and splitting into training and validation  \n",
    "    df = pd.read_csv('assets/train.csv', index_col=0)\n",
    "    X = df.iloc[:,:-1]\n",
    "    y = df.iloc[:,-1]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "    \n",
    "    test = pd.read_csv('assets/test.csv', index_col=0)\n",
    "    \n",
    "    \n",
    "    # grid search decision tree\n",
    "    clf = DecisionTreeClassifier()\n",
    "    grid_values = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'ccp_alpha': [0.1, .01, .001],\n",
    "              'max_depth' : [5, 6, 7, 8, 9],\n",
    "              'criterion' :['gini', 'entropy'] }\n",
    "    grid_search(clf, grid_values, X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # classifier with best gridsearch hyperparams based on previous grid search\n",
    "    clf = DecisionTreeClassifier(ccp_alpha= 0.001, criterion = 'entropy', max_depth= 5, max_features = 'sqrt').fit(X_train, y_train)\n",
    "    print('AUC SCORE (test): {0:.3f}'.format(roc_auc_score(y_val, clf.predict_proba(X_val)[:, 1])))\n",
    "    \n",
    "    data = clf.predict_proba(test)[:, 1]\n",
    "    result = pd.Series(data, index = test.index) \n",
    "    \n",
    "    return result\n",
    "    \n",
    "    \n",
    "   \n",
    "engagement_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42118464",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26a7c364781ea24c8e46c623e73c1d4a",
     "grade": true,
     "grade_id": "cell-df6ac3eec5bb54f7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
